<!doctype html><html lang=en><head><meta http-equiv=content-type content="text/html" charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#ffffff"><title itemprop=name>Quantum Enhanced Image Classification with Hybrid Quantum-Classical Neural Networks | Breezy Byters</title><meta name=description content="Innovative Solutions, Effortless Execution"><meta property="og:title" content="Quantum Enhanced Image Classification with Hybrid Quantum-Classical Neural Networks | Breezy Byters"><meta name=twitter:title content="Quantum Enhanced Image Classification with Hybrid Quantum-Classical Neural Networks | Breezy Byters"><meta itemprop=name content="Quantum Enhanced Image Classification with Hybrid Quantum-Classical Neural Networks | Breezy Byters"><meta name=application-name content="Quantum Enhanced Image Classification with Hybrid Quantum-Classical Neural Networks | Breezy Byters"><meta property="og:site_name" content="Breezy Byters"><meta property="og:type" content="website"><meta property="og:title" content="Breezy Byters"><meta property="og:description" content="Innovative Solutions, Effortless Execution"><meta property="og:site_name" content="Breezy Byters"><meta property="og:url" content="https://breezybyters.github.io/posts/qeichqcnn/"><meta property="og:locale" content="en"><meta property="og:image" content="/images/tailbliss-cover.png"><meta property="og:image:secure_url" content="https://breezybyters.github.io/images/tailbliss-cover.png"><meta property="og:type" content="website"><script>localStorage.getItem("color-theme")==="dark"||!("color-theme"in localStorage)&&window.matchMedia("(prefers-color-scheme: dark)").matches?document.documentElement.classList.add("dark"):document.documentElement.classList.remove("dark")</script><link rel=stylesheet href="/css/style.min.2655e72f2dd857142d1bfce38afd3a33dfad3a6c0d155d3a0f6702da5beb5132.css" integrity="sha256-JlXnLy3YVxQtG/zjiv06M9+tOmwNFV06D2cC2lvrUTI="></head><body class="bg-zinc-100 dark:bg-gray-800 scrollbar-thin scrollbar-thumb-rose-500 scrollbar-track-slate-700"><div class="top-0 z-50 w-full text-gray-200 bg-gray-900 border-2 border-gray-900 md:sticky border-b-stone-200/10"><div x-data="{ open: false }" class="flex flex-col max-w-full px-4 mx-auto md:items-center md:justify-between md:flex-row md:px-6 lg:px-8"><div class="flex flex-row items-center justify-between p-4"><a href=https://breezybyters.github.io/ class="flex text-gray-100 transition duration-1000 ease-in-out group"><div class=blob-animation></div><div class="mt-1 ml-3 text-xl font-black tracking-tight text-gray-100 uppercase transition-colors group-hover:text-gray-400/60 font-primal">Breezy Byters</div></a><button class="rounded-lg md:hidden focus:outline-none focus:shadow-outline" @click="open = !open" role=navigation aria-expanded=false aria-label=Main aria-controls=menuItems><svg fill="currentcolor" viewBox="0 0 20 20" class="w-6 h-6"><path x-show="!open" fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4A1 1 0 013 5zm0 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zm6 5a1 1 0 011-1h6a1 1 0 110 2h-6a1 1 0 01-1-1z" clip-rule="evenodd"/><path x-show="open" fill-rule="evenodd" d="M4.293 4.293a1 1 0 011.414.0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z" clip-rule="evenodd"/></svg></button></div><nav :class="{'flex': open, 'hidden': !open}" class="flex-col flex-grow hidden pb-4 md:pb-0 md:flex md:justify-end md:flex-row"><a class="px-4 py-2 mt-2 text-sm font-semibold rounded-lg md:mt-0 md:ml-4 hover:text-white focus:text-white hover:bg-primary-600 focus:bg-primary-700 focus:outline-none focus:shadow-outline transition-colors" href=https://breezybyters.github.io/about/>About</a><div @click.away="open = false" class=relative x-data="{ open: false }"><button @click="open = !open" class="flex flex-row items-center w-full px-4 py-2 mt-2 text-sm font-semibold text-left bg-transparent rounded-lg dark-mode:focus:text-white dark-mode:hover:text-white dark-mode:focus:bg-gray-600 dark-mode:hover:bg-gray-600 md:w-auto md:inline md:mt-0 md:ml-4 hover:text-white focus:text-white hover:bg-primary-600 focus:bg-primary-600 focus:outline-none focus:shadow-outline transition-colors">
<span>Posts</span><svg fill="currentcolor" viewBox="0 0 20 20" :class="{'rotate-180': open, 'rotate-0': !open}" class="inline w-4 h-4 mt-1 ml-1 transition-transform duration-200 transform md:-mt-1"><path fill-rule="evenodd" d="M5.293 7.293a1 1 0 011.414.0L10 10.586l3.293-3.293a1 1 0 111.414 1.414l-4 4a1 1 0 01-1.414.0l-4-4a1 1 0 010-1.414z" clip-rule="evenodd"/></svg></button><div x-show=open x-transition:enter="transition ease-out duration-100" x-transition:enter-start="transform opacity-0 scale-95" x-transition:enter-end="transform opacity-100 scale-100" x-transition:leave="transition ease-in duration-75" x-transition:leave-start="transform opacity-100 scale-100" x-transition:leave-end="transform opacity-0 scale-95" style=display:none class="absolute right-0 z-30 w-full mt-2 origin-top-right md:max-w-sm md:w-screen"><div class="px-2 pt-2 pb-4 bg-white rounded-md shadow-lg text-zinc-900"><div class="grid grid-cols-1 gap-4"><a class="flex items-start p-2 bg-transparent rounded-lg group row hover:text-white focus:text-white hover:bg-primary-600 focus:bg-primary-700 focus:outline-none focus:shadow-outline" href=https://breezybyters.github.io/categories/projects/><div class="p-3 text-white bg-primary-600 rounded-lg group-hover:bg-gray-900"><svg fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" class="w-4 h-4 md:h-6 md:w-6"><path d="M5 3v4M3 5h4M6 17v4m-2-2h4m5-16 2.286 6.857L21 12l-5.714 2.143L13 21l-2.286-6.857L5 12l5.714-2.143L13 3z"/></svg></div><div class=ml-3><p class=font-semibold>Projects</p><p class=text-sm>Cool stuff</p></div></a><a class="flex items-start p-2 bg-transparent rounded-lg group row hover:text-white focus:text-white hover:bg-primary-600 focus:bg-primary-700 focus:outline-none focus:shadow-outline" href=https://breezybyters.github.io/categories/news/><div class="p-3 text-white bg-primary-600 rounded-lg group-hover:bg-gray-900"><svg fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" class="w-4 h-4 md:h-6 md:w-6"><path d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 4.418-4.03 8-9 8a9.863 9.863.0 01-4.255-.949L3 20l1.395-3.72C3.512 15.042 3 13.574 3 12c0-4.418 4.03-8 9-8s9 3.582 9 8z"/></svg></div><div class=ml-3><p class=font-semibold>News</p><p class=text-sm>Current events</p></div></a></div></div></div></div><a class="px-4 py-2 mt-2 text-sm font-semibold bg-transparent rounded-lg md:mt-0 md:ml-4 hover:text-white focus:text-white hover:bg-primary-600 focus:bg-primary-700 focus:outline-none focus:shadow-outline transition-colors" href=https://breezybyters.github.io/contact>Contact</a>
<button id=theme-toggle type=button class="p-2 text-sm text-gray-500 rounded-lg md: dark:text-gray-400 hover:bg-gray-100 dark:hover:bg-gray-700 focus:outline-none focus:ring-gray-200 dark:focus:ring-gray-700 md:ml-2 max-w-5 xs:hidden transition-all"><svg id="theme-toggle-dark-icon" class="hidden w-5 h-5" fill="currentcolor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001.0 1010.586 10.586z"/></svg><svg id="theme-toggle-light-icon" class="hidden w-5 h-5" fill="currentcolor" viewBox="0 0 20 20" aria-label="Dark or Light Mode" xmlns="http://www.w3.org/2000/svg"><path d="M10 2a1 1 0 011 1v1A1 1 0 119 4V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707A1 1 0 1113.536 5.05l.707-.707a1 1 0 011.414.0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707A1 1 0 004.343 5.757l.707.707zm1.414 8.486-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule="evenodd" clip-rule="evenodd"/></svg></button></nav></div></div><article><header class="mb-4 bg-primary-600"><span class=py-96><h1 class="py-16 text-5xl font-black text-center text-white capitalize">Quantum Enhanced Image Classification with Hybrid Quantum-Classical Neural Networks</h1></span></header><div class="max-w-4xl mx-auto mt-8 mb-2"><div class=px-6></div></div><div class="max-w-2xl px-6 pt-6 pb-16 mx-auto prose dark:prose-invert dark:text-white"><h1 id=introduction>Introduction</h1><p>As machine learning continues to make significant strides in various domains, researchers are constantly exploring methods to improve its performance and efficiency. One such avenue is the incorporation of quantum computing into machine learning models. Quantum computing, leveraging the principles of quantum mechanics, has the potential to provide exponential speed-ups and enhanced performance over classical computing in certain tasks.</p><p>In this blog post, we will discuss a quantum machine learning project that combines classical deep learning and quantum computing to build a hybrid quantum-classical neural network for image classification. We will cover the motivation, implementation, and results of this exciting project, including Python code examples, research references, and relevant links and images.</p><p><img src=https://qiskit.org/textbook/ch-machine-learning/hybridnetwork.png alt="Hybrid Quantum-Classical Neural Network"></p><h1 id=motivation-why-quantum-machine-learning>Motivation: Why Quantum Machine Learning?</h1><p>Quantum computing is an emerging field that has shown promising results in solving problems that are intractable for classical computers. Quantum machine learning (QML) is the intersection of quantum computing and machine learning, where quantum algorithms and principles are applied to machine learning tasks for potential performance improvements.</p><p>While classical machine learning, particularly deep learning, has achieved remarkable results in various tasks like image classification, it still faces limitations in terms of computational complexity and scalability. Quantum machine learning can potentially address these challenges by leveraging quantum parallelism and quantum entanglement, leading to more efficient and accurate models.</p><p>Some recent research in this area includes:</p><ul><li><a href=https://www.nature.com/articles/nature23474>Quantum Machine Learning</a> by Jacob Biamonte et al.</li><li><a href=https://www.researchgate.net/publication/312759829_A_Survey_of_Quantum_Learning_Theory>A Survey of Quantum Learning Theory</a> by Seth Lloyd et al.</li><li><a href=https://learn.qiskit.org/course/ch-applications/hybrid-quantum-classical-neural-networks-with-pytorch-and-qiskit>Hybrid Quantum-Classical Neural Networks with PyTorch and Qiskit</a>.</li></ul><h1 id=project-overview-hybrid-quantum-classical-neural-networks-for-image-classification>Project Overview: Hybrid Quantum-Classical Neural Networks for Image Classification</h1><p>The goal of this project is to develop a hybrid quantum-classical neural network for image classification, combining the strengths of classical deep learning and quantum computing. Specifically, we use a classical convolutional neural network (CNN) for feature extraction from input images and a quantum neural network (QNN) for processing the extracted features.</p><h2 id=classical-cnn-for-feature-extraction>Classical CNN for Feature Extraction</h2><p>Convolutional neural networks are a type of deep learning model specifically designed for image processing tasks. They consist of multiple layers, including convolutional layers, pooling layers, and fully connected layers, that enable the CNN to learn hierarchical features from input images. In our project, we use a classical CNN to process raw image data and extract meaningful features to be passed on to the QNN.</p><p>Here&rsquo;s a simple example of a CNN using TensorFlow and Keras:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> tensorflow <span style=color:#66d9ef>as</span> tf
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras <span style=color:#f92672>import</span> layers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_cnn</span>(input_shape):
</span></span><span style=display:flex><span>    model <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>Sequential([
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>Conv2D(<span style=color:#ae81ff>32</span>, kernel_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>, input_shape<span style=color:#f92672>=</span>input_shape),
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>MaxPooling2D(pool_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)),
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>Conv2D(<span style=color:#ae81ff>64</span>, kernel_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>Max
</span></span><span style=display:flex><span>        Pooling2D(pool_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)),
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>Flatten(),
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>128</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>10</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;softmax&#39;</span>)
</span></span><span style=display:flex><span>    ])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    model<span style=color:#f92672>.</span>compile(optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;adam&#39;</span>, loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;categorical_crossentropy&#39;</span>, metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;accuracy&#39;</span>])
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> model
</span></span></code></pre></div><h3 id=quantum-neural-network-for-feature-processing>Quantum Neural Network for Feature Processing</h3><p>Once the CNN extracts features from the input images, we use a quantum neural network to process these features. A QNN is a quantum analog of a classical neural network, leveraging quantum gates and qubits to perform complex operations. We implement the QNN using a quantum computing framework such as Qiskit, PennyLane, or TensorFlow Quantum.</p><p>Here&rsquo;s an example of a simple QNN layer using PennyLane:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> pennylane <span style=color:#66d9ef>as</span> qml
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pennylane <span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>qnn_layer</span>(params, inputs):
</span></span><span style=display:flex><span>    num_qubits <span style=color:#f92672>=</span> len(inputs)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(num_qubits):
</span></span><span style=display:flex><span>        qml<span style=color:#f92672>.</span>RY(np<span style=color:#f92672>.</span>pi <span style=color:#f92672>*</span> inputs[i], wires<span style=color:#f92672>=</span>i)
</span></span><span style=display:flex><span>        qml<span style=color:#f92672>.</span>RZ(params[<span style=color:#ae81ff>0</span>][i], wires<span style=color:#f92672>=</span>i)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    qml<span style=color:#f92672>.</span>broadcast(qml<span style=color:#f92672>.</span>CNOT, wires<span style=color:#f92672>=</span>range(num_qubits), pattern<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;ring&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(num_qubits):
</span></span><span style=display:flex><span>        qml<span style=color:#f92672>.</span>RY(params[<span style=color:#ae81ff>1</span>][i], wires<span style=color:#f92672>=</span>i)
</span></span></code></pre></div><h3 id=combining-cnn-and-qnn>Combining CNN and QNN</h3><p>To create a hybrid quantum-classical neural network, we need to integrate the classical CNN with the quantum neural network. One way to achieve this is by using the output of the CNN as input to the QNN. Here&rsquo;s an example using TensorFlow and PennyLane:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> tensorflow <span style=color:#66d9ef>as</span> tf
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pennylane <span style=color:#66d9ef>as</span> qml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create a quantum device</span>
</span></span><span style=display:flex><span>dev <span style=color:#f92672>=</span> qml<span style=color:#f92672>.</span>device(<span style=color:#e6db74>&#34;default.qubit&#34;</span>, wires<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Define the QNode</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@qml.qnode</span>(dev)
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>qnn</span>(params, inputs):
</span></span><span style=display:flex><span>    qnn_layer(params, inputs)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> [qml<span style=color:#f92672>.</span>expval(qml<span style=color:#f92672>.</span>PauliZ(i)) <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>4</span>)]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Define the hybrid model</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_hybrid_model</span>(input_shape):
</span></span><span style=display:flex><span>    cnn <span style=color:#f92672>=</span> create_cnn(input_shape)
</span></span><span style=display:flex><span>    qnn_layer <span style=color:#f92672>=</span> qml<span style=color:#f92672>.</span>qnn<span style=color:#f92672>.</span>KerasLayer(qnn, {<span style=color:#e6db74>&#34;params&#34;</span>: (<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>4</span>)}, output_dim<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    model <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>Sequential([
</span></span><span style=display:flex><span>        cnn,
</span></span><span style=display:flex><span>        layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>4</span>),
</span></span><span style=display:flex><span>        qnn_layer
</span></span><span style=display:flex><span>    ])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    model<span style=color:#f92672>.</span>compile(optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;adam&#39;</span>, loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;categorical_crossentropy&#39;</span>, metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;accuracy&#39;</span>])
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> model
</span></span></code></pre></div><h3 id=training-and-evaluation>Training and Evaluation</h3><p>To train and evaluate the hybrid quantum-classical neural network, we use a suitable image dataset like CIFAR-10 or MNIST. We benchmark the classification performance of our hybrid model against a purely classical deep learning model, aiming to demonstrate the potential benefits of incorporating quantum computing into machine learning tasks.</p><p>Here&rsquo;s an example of training the hybrid model using the CIFAR-10 dataset:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras.datasets <span style=color:#f92672>import</span> cifar10
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras.utils <span style=color:#f92672>import</span> to_categorical
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Load the dataset</span>
</span></span><span style=display:flex><span>(x_train, y_train), (x_test, y_test) <span style=color:#f92672>=</span> cifar10<span style=color:#f92672>.</span>load_data()
</span></span><span style=display:flex><span>x_train <span style=color:#f92672>=</span> x_train <span style=color:#f92672>/</span> <span style=color:#ae81ff>255.0</span>
</span></span><span style=display:flex><span>x_test <span style=color:#f92672>=</span> x_test <span style=color:#f92672>/</span> <span style=color:#ae81ff>255.0</span>
</span></span><span style=display:flex><span>y_train <span style=color:#f92672>=</span> to_categorical(y_train, <span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>y_test <span style=color:#f92672>=</span> to_categorical(y_test, <span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create the hybrid model</span>
</span></span><span style=display:flex><span>input_shape <span style=color:#f92672>=</span> x_train<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>:]
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> create_hybrid_model(input_shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Train the model</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(x_train, y_train, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>, validation_data<span style=color:#f92672>=</span>(x_test, y_test))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Evaluate the model</span>
</span></span><span style=display:flex><span>loss, accuracy <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>evaluate(x_test, y_test)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Test accuracy: </span><span style=color:#e6db74>{</span>accuracy<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><h2 id=results-and-future-directions>Results and Future Directions</h2><p>After implementing and training our hybrid quantum-classical neural network, we analyze the results and compare the classification performance with a purely classical model. If successful, our hybrid model will demonstrate enhanced performance and efficiency compared to the classical model.</p><p>Potential future research directions include exploring different quantum algorithms, optimizing the hybrid model&rsquo;s architecture, and investigating other quantum-enhanced machine learning tasks. The project serves as an excellent starting point for those interested in quantum machine learning and showcases the potential of quantum computing in enhancing real-world applications.</p><h2 id=conclusion>Conclusion</h2><p>In this blog post, we discussed a quantum machine learning project that combines classical deep learning and quantum computing to build a hybrid quantum-classical neural network for image classification. By leveraging the unique properties of quantum computing, this project aims to showcase the potential of quantum-enhanced machine learning, paving the way for further advancements in the field.</p></div></article><script src=https://breezybyters.github.io/js/alpine.js defer></script>
<script src=https://breezybyters.github.io/js/darkmode.js defer></script>
<script src=https://breezybyters.github.io/js/scroll.js defer></script>
<script src=https://breezybyters.github.io/js/blob.js defer></script><div class="fixed bottom-0 left-0 w-full h-1 bg-gray-300 dark:bg-gray-700"><div class="h-full bg-gradient-to-r from-pink-400 via-purple-400 to-blue-400" id=progress-bar></div></div><script src=https://breezybyters.github.io/js/progress.js></script><footer class=bg-gray-900><div class="max-w-md px-4 py-12 mx-auto overflow-hidden sm:max-w-3xl sm:px-6 lg:max-w-7xl lg:px-8"><nav class="flex flex-wrap justify-center -mx-5 -my-2" aria-label=Footer><div class="px-5 py-2"><a href=https://breezybyters.github.io/about class="text-base text-gray-400 hover:text-gray-300 transition">About</a></div><div class="px-5 py-2"><a href=https://breezybyters.github.io/categories/projects/ class="text-base text-gray-400 hover:text-gray-300 transition">Projects</a></div><div class="px-5 py-2"><a href=https://breezybyters.github.io/categories/news/ class="text-base text-gray-400 hover:text-gray-300 transition">News</a></div><div class="px-5 py-2"><a href=https://breezybyters.github.io/contact/ class="text-base text-gray-400 hover:text-gray-300 transition">Contact</a></div></nav><div class="flex justify-center mt-8 space-x-6"><a href=https://github.com/breezybyters class="text-gray-400 hover:text-gray-300 transition"><span class=sr-only>GitHub</span><svg class="w-6 h-6" fill="currentcolor" viewBox="0 0 480 512" aria-hidden="true"><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8.0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8.0-21.5 4.9-32.3 14.6-51.8 45.3.0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8.0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9.0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2.0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8.0-73.5 38.7-73.5 82.6.0 87.8 80.4 101.3 150.4 101.3h48.2c70.3.0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8.0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg></a>
<a href=mailto:breezybyters@proton.me class="text-gray-400 hover:text-gray-300 transition"><span class=sr-only>Email</span><svg class="w-6 h-6" fill="currentcolor" viewBox="0 0 512 512" aria-hidden="true"><path fill-rule="evenodd" d="M48 64C21.5 64 0 85.5.0 112c0 15.1 7.1 29.3 19.2 38.4L236.8 313.6c11.4 8.5 27 8.5 38.4.0L492.8 150.4c12.1-9.1 19.2-23.3 19.2-38.4.0-26.5-21.5-48-48-48H48zM0 176V384c0 35.3 28.7 64 64 64H448c35.3.0 64-28.7 64-64V176L294.4 339.2c-22.8 17.1-54 17.1-76.8.0L0 176z" clip-rule="evenodd"/></svg></a></div><p class="mt-8 text-base text-center text-gray-400">&copy; 2023
Breezy Byters. All rights
reserved.</p></div></footer></body></html>